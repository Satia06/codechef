# -*- coding: utf-8 -*-
"""Satu.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EJu1KVAE7FP9I9_8NyqHGPkDdjLoC9ft
"""

from google.colab import drive
drive.mount('/content/gdrive')

import os
print(os.listdir('/content/gdrive/My Drive/'))

!unzip '/content/gdrive/My Drive/CV-20200627T143437Z-001.zip' -d'/content/gdrive/My Drive/'

import tensorflow as tf 
import numpy as np
import matplotlib.pyplot as plt 
from tensorflow.keras.optimizers import RMSprop 
from tensorflow.keras.preprocessing.image import ImageDataGenerator 
from google.colab import files 
from keras.preprocessing import image 
import random 
import os 
import shutil

def make_dir(path):

  try:
    os.makedirs(path)
    print('file created')
  except FileExistsError:
    print('the file already exists')

def remove_dir(path):
  try:
    os.rmtree(path)
    print('Folder created at {}'.format(path))
  except FileExistsError:
    print('file already exists')

main_dir = '/content/gdrive/My Drive/CV/train_set/'
categories = ['drawings','painting','engraving','iconography','sculpture']

for cat in categories:
  make_dir(str(main_dir+'train/'+'train_'+ cat ))
  make_dir(str(main_dir+ 'test/'+'test_'+ cat))

def split_data(source,train_dir,test_dir,split_size):
   shuffled_source = random.sample(os.listdir(source),len(os.listdir(source)))
   train_list = shuffled_source[: int(split_size*len(os.listdir(source)))]
   test_list = shuffled_source[int(split_size*len(os.listdir(source))) :]
   
   for files in train_list:
    shutil.copyfile(os.path.join(source,files),os.path.join(train_dir,files))

   for files in test_list:
     shutil.copyfile(os.path.join(source,files),os.path.join(test_dir,files))

split_data('/content/gdrive/My Drive/CV/train_set/drawings/','/content/gdrive/My Drive/CV/train_set/train_drawings','/content/gdrive/My Drive/CV/train_set/test_drawings',0.9)
split_data('/content/gdrive/My Drive/CV/train_set/painting/','/content/gdrive/My Drive/CV/train_set/train_painting','/content/gdrive/My Drive/CV/train_set/test_painting',0.9)
split_data('/content/gdrive/My Drive/CV/train_set/engraving/','/content/gdrive/My Drive/CV/train_set/train_engraving','/content/gdrive/My Drive/CV/train_set/test_engraving',0.9)
split_data('/content/gdrive/My Drive/CV/train_set/iconography/','/content/gdrive/My Drive/CV/train_set/train_iconography','/content/gdrive/My Drive/CV/train_set/test_iconography',0.9)
split_data('/content/gdrive/My Drive/CV/train_set/sculpture/','/content/gdrive/My Drive/CV/train_set/train_sculpture','/content/gdrive/My Drive/CV/train_set/test_sculpture',0.9)

model = tf.keras.models.Sequential(
    [
                        tf.keras.layers.Conv2D(16,(3,3),activation = 'relu',input_shape = (300,300,3)),
                        tf.keras.layers.MaxPooling2D(2,2),
                        tf.keras.layers.Conv2D(32,(3,3),activation = 'relu'),
                        tf.keras.layers. MaxPooling2D(2,2),
                        tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),
                        tf.keras.layers.MaxPooling2D(2,2),
                        tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),
                        tf.keras.layers.MaxPooling2D(2,2),
                        tf.keras.layers.Flatten(),
                        tf.keras.layers.Dense(512,activation = 'relu'),
                        tf.keras.layers.Dense(64,activation = 'relu'),
                        tf.keras.layers.Dense(5,activation = 'softmax'),
                        
    ]
)

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(lr=0.001),
              metrics=['accuracy']
              )

#data preprocessing
#using ImageDataGenerator

#all images will be rescaled.
train_datagen = ImageDataGenerator(rescale=1/255)
test_datagen = ImageDataGenerator(rescale=1/255)

train_generator = train_datagen.flow_from_directory('/content/gdrive/My Drive/CV/train_set/train/',
                                                    target_size=(300,300),
                                                    batch_size=64,
                                                    class_mode = 'categorical' )

test_generator = test_datagen.flow_from_directory('/content/gdrive/My Drive/CV/train_set/test/',
                                                  target_size = (300,300),
                                                  batch_size = 16,
                                                  class_mode = 'categorical')

history = model.fit(
          train_generator,
          steps_per_epoch = 29,
          epochs = 15,
          verbose = 1 ,
          validation_data = test_generator,
          validation_steps = 13
          )

acc      = history.history[     'accuracy' ]
val_acc  = history.history[ 'val_accuracy' ]
loss     = history.history[    'loss' ]
val_loss = history.history['val_loss' ]

epochs   = range(len(acc)) # Get number of epochs

plt.plot  ( epochs,     acc )
plt.plot  ( epochs, val_acc )
plt.title ('Training and validation accuracy')
plt.figure()

plt.plot  ( epochs,     loss )
plt.plot  ( epochs, val_loss )
plt.title ('Training and validation loss'   )